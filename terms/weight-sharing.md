---
title: Weight sharing
related_terms:
 - neural-network
references:
 - "[Simplifying Neural Networks by Soft Weight-Sharing](http://www.cs.toronto.edu/~fritz/absps/sunspots.pdf)"
 - "[Shared Weights - Convolutional Neural Networks - Deep Learning Tutorial](http://deeplearning.net/tutorial/lenet.html#shared-weights)"
 - "[Soft Weight-Sharing for Neural Network Compression](https://arxiv.org/abs/1702.04008)"
---
In neural networks, weight sharing is a way to reduce the number of parameters while allowing
for more robust feature detection. Reducing the number of parameters can be
considered a form of [model compression](/terms/model-compression/).
