---
title: Weak supervision
references:
- link_title: "Weak Supervision: A New Programming Paradigm for Machine Learning - The Stanford AI Lab Blog"
  link_url: https://ai.stanford.edu/blog/weak-supervision/
- link_title: "Snorkel and The Dawn of Weakly Supervised Machine Learning - Stanford DAWN"
  link_url: https://dawn.cs.stanford.edu/2017/05/08/snorkel/
- link_title: "Snuba: Automating Weak Supervision to Label Training Data - Stanford University"
  link_url: http://www.vldb.org/pvldb/vol12/p223-varma.pdf
- link_title: "Weak supervision - Wikipedia"
  link_url: https://en.wikipedia.org/wiki/Weak_supervision
related_terms:
- active-learning
- semi-supervised-learning
- transfer-learning
---
**Weak supervision** describes the use of noisy or error-prone data labels for training supervised learning models.

It can be expensive or impractical to create or obtain highly-accurate labels for a large dataset. Weak supervision offers the choice of using a larger number of somewhat-less-accurate data labels.
