---
references:
- link_title: Why doesn't backpropagation work when you initialize the weights the
    same value? -- Cross Validated
  link_url: https://stats.stackexchange.com/questions/45087/why-doesnt-backpropagation-work-when-you-initialize-the-weights-the-same-value
- link_title: Random Initialization - Coursera Machine Learning
  link_url: https://www.coursera.org/learn/machine-learning/lecture/ND5G5/random-initialization
related_terms:
- symmetry-breaking
title: Random initialization
---
Random initialization refers to the practice of using random numbers
to initialize the weights of a machine learning model.

Random initialization is one way of performing [symmetry breaking](/terms/symmetry-breaking), which is the act of preventing all of
the weights in the machine learning model from being the same.